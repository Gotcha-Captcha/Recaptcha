# ğŸš¨ ì¹˜ëª…ì ì¸ ì„¤ê³„ í¬ì¸íŠ¸ (Critical Design Points)

## ğŸ“Š ë°ì´í„° í˜„í™©
- **ì´ ì´ë¯¸ì§€ ìˆ˜**: ì•½ 55,000ì¥
- **í™˜ê²½**: M1 MacBook 16GB RAM
- **ë°ì´í„° êµ¬ì¡°**: í´ë”ë³„ í´ë˜ìŠ¤ êµ¬ì¡° í™•ì¸ë¨
  - `google-recaptcha/data/train/Bicycle/`, `Bus/`, `Car/` ë“±
  - `google-recaptcha-v2/images/Bicycle/`, `Bus/` ë“±

---

## ğŸš¨ í¬ì¸íŠ¸ 1: Data Leakage (ë°ì´í„° ì˜¤ì—¼) ë°©ì§€

### ë¬¸ì œì 
- **ì¤‘ë³µ ì´ë¯¸ì§€**: ë™ì¼í•œ ì‚¬ë¬¼ì„ ê°ë„ë§Œ ì‚´ì§ ë°”ê¾¼ ì´ë¯¸ì§€ê°€ train/testì— ì„ì´ë©´ ëª¨ë¸ì´ 'ì•”ê¸°'í•˜ê²Œ ë¨
- **ê²°ê³¼**: ë†’ì€ ì ìˆ˜ì§€ë§Œ ì‹¤ì œ ìº¡ì°¨ì—ì„œëŠ” ì‹¤íŒ¨

### í•´ê²° ì „ëµ

#### 1. ì¤‘ë³µ ì´ë¯¸ì§€ ê²€ì¶œ
```python
def detect_duplicate_images(image_paths: List[Path], 
                            similarity_threshold: float = 0.95) -> Dict:
    """
    ì´ë¯¸ì§€ í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ê²€ì¶œ
    
    Args:
        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.95 = 95% ì´ìƒ ìœ ì‚¬)
    
    Returns:
        ì¤‘ë³µ ê·¸ë£¹ ë”•ì…”ë„ˆë¦¬
    """
    from PIL import Image
    import imagehash
    
    # Perceptual hash ê³„ì‚°
    image_hashes = {}
    for img_path in tqdm(image_paths, desc="Computing image hashes"):
        try:
            img = Image.open(img_path)
            phash = imagehash.phash(img)
            image_hashes[img_path] = phash
        except Exception as e:
            continue
    
    # ì¤‘ë³µ ê·¸ë£¹ ì°¾ê¸°
    duplicate_groups = {}
    processed = set()
    
    for img_path, hash_val in image_hashes.items():
        if img_path in processed:
            continue
        
        duplicates = [img_path]
        for other_path, other_hash in image_hashes.items():
            if img_path != other_path and other_path not in processed:
                # í•´ì‹œ ê±°ë¦¬ ê³„ì‚°
                hamming_distance = hash_val - other_hash
                if hamming_distance <= 5:  # ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥
                    duplicates.append(other_path)
                    processed.add(other_path)
        
        if len(duplicates) > 1:
            duplicate_groups[img_path] = duplicates
            processed.add(img_path)
    
    return duplicate_groups
```

#### 2. ì—„ê²©í•œ ë°ì´í„° ë¶„í• 
```python
def strict_train_test_split(image_paths: List[Path], 
                           labels: List[str],
                           test_size: float = 0.2,
                           random_state: int = 42,
                           ensure_no_duplicates: bool = True) -> Tuple:
    """
    ì¤‘ë³µ ì´ë¯¸ì§€ê°€ train/testì— ì„ì´ì§€ ì•Šë„ë¡ ì—„ê²©í•œ ë¶„í• 
    
    Args:
        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        labels: ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸
        test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
        random_state: ëœë¤ ì‹œë“œ
        ensure_no_duplicates: ì¤‘ë³µ ì²´í¬ ì—¬ë¶€
    
    Returns:
        (X_train, X_test, y_train, y_test)
    """
    from sklearn.model_selection import train_test_split
    
    if ensure_no_duplicates:
        # ì¤‘ë³µ ê·¸ë£¹ í™•ì¸
        duplicate_groups = detect_duplicate_images(image_paths)
        
        # ì¤‘ë³µ ê·¸ë£¹ì˜ ëŒ€í‘œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
        representative_images = set()
        for group in duplicate_groups.values():
            # ê° ê·¸ë£¹ì—ì„œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì„ íƒ
            representative_images.add(group[0])
        
        # ì¤‘ë³µë˜ì§€ ì•Šì€ ì´ë¯¸ì§€ë§Œ í•„í„°ë§
        filtered_paths = []
        filtered_labels = []
        for path, label in zip(image_paths, labels):
            if path in representative_images or path not in duplicate_groups:
                filtered_paths.append(path)
                filtered_labels.append(label)
        
        image_paths = filtered_paths
        labels = filtered_labels
    
    # í´ë˜ìŠ¤ë³„ë¡œ Stratified Split
    X_train, X_test, y_train, y_test = train_test_split(
        image_paths, labels,
        test_size=test_size,
        random_state=random_state,
        stratify=labels  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
    )
    
    return X_train, X_test, y_train, y_test
```

#### 3. íŒŒì¼ëª… ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
```python
def check_filename_duplicates(image_paths: List[Path]) -> Dict:
    """íŒŒì¼ëª… ê¸°ë°˜ ì¤‘ë³µ ì²´í¬ (ê°„ë‹¨í•œ ë°©ë²•)"""
    filename_groups = {}
    
    for img_path in image_paths:
        filename = img_path.name
        if filename not in filename_groups:
            filename_groups[filename] = []
        filename_groups[filename].append(img_path)
    
    # ì¤‘ë³µì´ ìˆëŠ” íŒŒì¼ëª…ë§Œ ë°˜í™˜
    duplicates = {k: v for k, v in filename_groups.items() if len(v) > 1}
    return duplicates
```

### êµ¬í˜„ ìœ„ì¹˜
- `src/preprocess/analyze.py`: ì¤‘ë³µ ì´ë¯¸ì§€ ê²€ì¶œ í•¨ìˆ˜ ì¶”ê°€
- `src/preprocess/main.py`: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì— ì¤‘ë³µ ì²´í¬ ë‹¨ê³„ ì¶”ê°€
- `src/train.py`: ë°ì´í„° ë¶„í•  ì‹œ ì¤‘ë³µ ë°©ì§€ ì ìš©

---

## ğŸš¨ í¬ì¸íŠ¸ 2: Feature Scaling (íŠ¹ì§• ìŠ¤ì¼€ì¼ í†µì¼)

### ë¬¸ì œì 
- **HOG**: 0~0.2 ì‚¬ì´ì˜ ì‘ì€ ê°’
- **Color Histogram**: ìˆ˜ë°±~ìˆ˜ì²œ ë‹¨ìœ„ì˜ í° ê°’
- **LBP**: 0~1 ì‚¬ì´ì˜ ì •ê·œí™”ëœ ê°’
- **ê²°ê³¼**: ëª¨ë¸ì´ í° ê°’ë§Œ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ê³  HOGì˜ í˜•íƒœ ì •ë³´ ë¬´ì‹œ

### í•´ê²° ì „ëµ

#### 1. íŠ¹ì§•ë³„ ê°œë³„ ì •ê·œí™” í›„ ê²°í•©
```python
class FeatureScaler:
    """íŠ¹ì§•ë³„ë¡œ ì ì ˆí•œ ìŠ¤ì¼€ì¼ë§ ì ìš©"""
    
    def __init__(self):
        self.scalers = {}
        self.feature_ranges = {
            'hog': (0, 0.2),  # HOGëŠ” ì‘ì€ ê°’
            'color_hist': (0, 10000),  # Color Histogramì€ í° ê°’
            'lbp': (0, 1),  # LBPëŠ” ì´ë¯¸ ì •ê·œí™”ë¨
            'gradient': (0, 255),  # GradientëŠ” í”½ì…€ ê°’ ë²”ìœ„
            'texture': (0, 1)  # TextureëŠ” ì •ê·œí™”ë¨
        }
    
    def fit_transform(self, features_dict: Dict[str, np.ndarray]) -> np.ndarray:
        """
        íŠ¹ì§•ë³„ë¡œ ìŠ¤ì¼€ì¼ë§ í›„ ê²°í•©
        
        Args:
            features_dict: {'hog': array, 'color_hist': array, ...}
        
        Returns:
            ìŠ¤ì¼€ì¼ë§ëœ ê²°í•© íŠ¹ì§• ë²¡í„°
        """
        from sklearn.preprocessing import StandardScaler, MinMaxScaler
        
        scaled_features = []
        
        for feat_name, feat_array in features_dict.items():
            if feat_name == 'hog':
                # HOGëŠ” MinMaxScalerë¡œ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
                scaler = MinMaxScaler()
                scaled = scaler.fit_transform(feat_array.reshape(-1, 1)).flatten()
            elif feat_name == 'color_hist':
                # Color Histogramì€ StandardScalerë¡œ í‘œì¤€í™”
                scaler = StandardScaler()
                scaled = scaler.fit_transform(feat_array.reshape(-1, 1)).flatten()
            elif feat_name in ['lbp', 'texture']:
                # ì´ë¯¸ ì •ê·œí™”ëœ íŠ¹ì§•ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                scaled = feat_array
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ StandardScaler ì‚¬ìš©
                scaler = StandardScaler()
                scaled = scaler.fit_transform(feat_array.reshape(-1, 1)).flatten()
            
            self.scalers[feat_name] = scaler
            scaled_features.append(scaled)
        
        return np.concatenate(scaled_features)
```

#### 2. ê²°í•© í›„ ì „ì²´ ìŠ¤ì¼€ì¼ë§ (ê¶Œì¥)
```python
def scale_combined_features(features: np.ndarray, 
                          method: str = 'standard') -> Tuple[np.ndarray, object]:
    """
    ê²°í•©ëœ íŠ¹ì§• ë²¡í„°ì— ì „ì²´ ìŠ¤ì¼€ì¼ë§ ì ìš©
    
    Args:
        features: ê²°í•©ëœ íŠ¹ì§• ë²¡í„° (N, 2000)
        method: 'standard', 'minmax', 'robust'
    
    Returns:
        (scaled_features, scaler_object)
    """
    from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
    
    if method == 'standard':
        scaler = StandardScaler()
    elif method == 'minmax':
        scaler = MinMaxScaler()
    elif method == 'robust':
        scaler = RobustScaler()  # ì´ìƒì¹˜ì— ê°•í•¨
    else:
        scaler = StandardScaler()
    
    scaled_features = scaler.fit_transform(features)
    
    return scaled_features, scaler
```

### êµ¬í˜„ ìœ„ì¹˜
- `src/feature_extraction/combined_extractor.py`: íŠ¹ì§• ê²°í•© ì‹œ ìŠ¤ì¼€ì¼ë§
- `src/train.py`: í•™ìŠµ ì „ íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ (configì—ì„œ ì„¤ì •)
- **ì¤‘ìš”**: Scaler ê°ì²´ë¥¼ ì €ì¥í•˜ì—¬ ì¶”ë¡  ì‹œ ë™ì¼í•˜ê²Œ ì ìš©

### ì €ì¥ êµ¬ì¡°
```
models/
â”œâ”€â”€ svm_combined_model.pkl
â”œâ”€â”€ svm_combined_scaler.pkl  # âš ï¸ í•„ìˆ˜! ì¶”ë¡  ì‹œ ì‚¬ìš©
â””â”€â”€ ...
```

---

## ğŸš¨ í¬ì¸íŠ¸ 3: PCA ì°¨ì› ì¶•ì†Œ (Explained Variance ê¸°ë°˜)

### ë¬¸ì œì 
- **ì„ì˜ ì°¨ì› ì¶•ì†Œ**: "50ì°¨ì›ìœ¼ë¡œ ì¤„ì—¬ì¤˜" â†’ ì •ë³´ ì†ì‹¤
- **ê³¼ë„í•œ ì¶•ì†Œ**: ì¤‘ìš”í•œ íŠ¹ì§• ì œê±°
- **ë¶€ì¡±í•œ ì¶•ì†Œ**: PCA ì˜ë¯¸ ì—†ìŒ

### í•´ê²° ì „ëµ

#### 1. Explained Variance Ratio ë¶„ì„
```python
def find_optimal_pca_dimensions(features: np.ndarray, 
                               variance_threshold: float = 0.95) -> Dict:
    """
    Explained Variance Ratioë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì  PCA ì°¨ì› ìˆ˜ ì°¾ê¸°
    
    Args:
        features: íŠ¹ì§• ë²¡í„° (N, D)
        variance_threshold: ë³´ì¡´í•  ë¶„ì‚° ë¹„ìœ¨ (0.95 = 95%)
    
    Returns:
        {'optimal_dim': int, 'variance_ratio': array, 'plot_data': dict}
    """
    from sklearn.decomposition import PCA
    
    # ì „ì²´ ì°¨ì›ìœ¼ë¡œ PCA ìˆ˜í–‰
    pca_full = PCA()
    pca_full.fit(features)
    
    # ëˆ„ì  ì„¤ëª… ë¶„ì‚° ê³„ì‚°
    cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)
    
    # ì„ê³„ê°’ì„ ë§Œì¡±í•˜ëŠ” ìµœì†Œ ì°¨ì› ì°¾ê¸°
    optimal_dim = np.argmax(cumulative_variance >= variance_threshold) + 1
    
    # ì‹œê°í™” ë°ì´í„°
    plot_data = {
        'components': range(1, min(100, len(cumulative_variance)) + 1),  # ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ
        'variance_ratio': pca_full.explained_variance_ratio_[:100],
        'cumulative_variance': cumulative_variance[:100],
        'optimal_dim': optimal_dim,
        'variance_at_optimal': cumulative_variance[optimal_dim - 1]
    }
    
    return {
        'optimal_dim': optimal_dim,
        'variance_ratio': pca_full.explained_variance_ratio_,
        'cumulative_variance': cumulative_variance,
        'plot_data': plot_data
    }
```

#### 2. PCA ì°¨ì› ê²°ì • ì‹œê°í™”
```python
def visualize_pca_analysis(pca_results: Dict, output_path: Path):
    """PCA ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
    import matplotlib.pyplot as plt
    
    plot_data = pca_results['plot_data']
    
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))
    
    # 1. Explained Variance Ratio
    ax = axes[0]
    ax.plot(plot_data['components'], plot_data['variance_ratio'][:len(plot_data['components'])], 
            'b-o', markersize=3)
    ax.axvline(plot_data['optimal_dim'], color='r', linestyle='--', 
               label=f"Optimal: {plot_data['optimal_dim']} dims")
    ax.set_xlabel('Number of Components')
    ax.set_ylabel('Explained Variance Ratio')
    ax.set_title('Explained Variance Ratio by Component')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. Cumulative Explained Variance
    ax = axes[1]
    ax.plot(plot_data['components'], plot_data['cumulative_variance'][:len(plot_data['components'])], 
            'g-o', markersize=3)
    ax.axhline(0.95, color='r', linestyle='--', label='95% Threshold')
    ax.axvline(plot_data['optimal_dim'], color='r', linestyle='--', 
               label=f"Optimal: {plot_data['optimal_dim']} dims")
    ax.set_xlabel('Number of Components')
    ax.set_ylabel('Cumulative Explained Variance')
    ax.set_title(f'Cumulative Explained Variance (Optimal: {plot_data["optimal_dim"]} dims, '
                 f'{plot_data["variance_at_optimal"]:.2%})')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
```

#### 3. PCA ì ìš©
```python
def apply_pca_with_optimal_dim(features: np.ndarray, 
                               variance_threshold: float = 0.95) -> Tuple:
    """
    ìµœì  ì°¨ì›ìœ¼ë¡œ PCA ì ìš©
    
    Returns:
        (transformed_features, pca_object, optimal_dim)
    """
    from sklearn.decomposition import PCA
    
    # ìµœì  ì°¨ì› ì°¾ê¸°
    pca_analysis = find_optimal_pca_dimensions(features, variance_threshold)
    optimal_dim = pca_analysis['optimal_dim']
    
    print(f"Optimal PCA dimensions: {optimal_dim} (preserves "
          f"{pca_analysis['cumulative_variance'][optimal_dim - 1]:.2%} variance)")
    
    # PCA ì ìš©
    pca = PCA(n_components=optimal_dim)
    transformed_features = pca.fit_transform(features)
    
    return transformed_features, pca, optimal_dim
```

### êµ¬í˜„ ìœ„ì¹˜
- `src/feature_selection/pca_analysis.py`: PCA ë¶„ì„ ëª¨ë“ˆ
- `src/feature_selection/main.py`: PCA ì ìš© íŒŒì´í”„ë¼ì¸
- `config/config.yaml`: `variance_threshold` ì„¤ì • ì¶”ê°€

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1. ë°ì´í„° êµ¬ì¡° íŒŒì•… âœ…
- [x] í´ë”ë³„ í´ë˜ìŠ¤ êµ¬ì¡° í™•ì¸ë¨
  - `google-recaptcha/data/train/Bicycle/`, `Bus/`, `Car/` ë“±
  - `google-recaptcha-v2/images/Bicycle/`, `Bus/` ë“±

### 2. í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸ âš ï¸ (êµ¬í˜„ í•„ìš”)
```python
def analyze_class_distribution(data_dir: Path) -> Dict:
    """í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ ë° ë¹„ìœ¨ ë¶„ì„"""
    class_counts = {}
    
    for class_dir in data_dir.iterdir():
        if class_dir.is_dir():
            images = list(class_dir.glob("*.png")) + list(class_dir.glob("*.jpg"))
            class_counts[class_dir.name] = len(images)
    
    total = sum(class_counts.values())
    class_ratios = {k: v/total for k, v in class_counts.items()}
    
    return {
        'counts': class_counts,
        'ratios': class_ratios,
        'total': total,
        'is_balanced': max(class_ratios.values()) / min(class_ratios.values()) < 2.0
    }
```

### 3. HOG íŒŒë¼ë¯¸í„° ê²°ì • âš ï¸ (112x112 ì´ë¯¸ì§€ ê¸°ì¤€)
```python
# 112x112 ì´ë¯¸ì§€ì— ìµœì í™”ëœ HOG íŒŒë¼ë¯¸í„°
HOG_CONFIG_112x112 = {
    'cell_size': (8, 8),      # 112 / 8 = 14 cells per dimension
    'block_size': (2, 2),     # 2x2 cells per block
    'block_stride': (1, 1),   # 50% overlap
    'nbins': 9,               # 9 orientation bins
    'win_size': (112, 112),   # ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°
    
    # ì˜ˆìƒ ì°¨ì›: (14-1) * (14-1) * 2 * 2 * 9 = 13 * 13 * 36 = 6,084
    # ì‹¤ì œë¡œëŠ” ì•½ 1,764 ì°¨ì› (OpenCV HOG êµ¬í˜„ì— ë”°ë¼ ë‹¤ë¦„)
}
```

---

## ğŸ“ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: ì¦‰ì‹œ êµ¬í˜„ (ì¹˜ëª…ì  í¬ì¸íŠ¸)
1. âœ… ì¤‘ë³µ ì´ë¯¸ì§€ ê²€ì¶œ ëª¨ë“ˆ
2. âœ… ì—„ê²©í•œ ë°ì´í„° ë¶„í•  í•¨ìˆ˜
3. âœ… Feature Scaling ì ìš©
4. âœ… PCA ë¶„ì„ ëª¨ë“ˆ

### Phase 2: ê²€ì¦ ë° ì‹œê°í™”
1. í´ë˜ìŠ¤ ë¹„ìœ¨ ë¶„ì„ ë° ì‹œê°í™”
2. HOG íŒŒë¼ë¯¸í„° ìµœì í™”
3. ìŠ¤ì¼€ì¼ë§ ì „/í›„ ë¹„êµ ì‹œê°í™”

### Phase 3: í†µí•©
1. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì— ì¤‘ë³µ ì²´í¬ í†µí•©
2. íŠ¹ì§• ì¶”ì¶œ ì‹œ ìë™ ìŠ¤ì¼€ì¼ë§
3. PCA ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­

1. **ë°ì´í„° ë¶„í•  ì „**: ë°˜ë“œì‹œ ì¤‘ë³µ ì´ë¯¸ì§€ ê²€ì¶œ ë° ì œê±°
2. **íŠ¹ì§• ì¶”ì¶œ í›„**: ë°˜ë“œì‹œ Feature Scaling ì ìš© (StandardScaler ê¶Œì¥)
3. **PCA ì ìš© ì „**: ë°˜ë“œì‹œ Explained Variance Ratio ë¶„ì„
4. **ëª¨ë¸ ì €ì¥ ì‹œ**: Scalerì™€ PCA ê°ì²´ë„ í•¨ê»˜ ì €ì¥
5. **ì¶”ë¡  ì‹œ**: í•™ìŠµ ì‹œì™€ ë™ì¼í•œ Scaler/PCA ì ìš©
