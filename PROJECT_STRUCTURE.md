# reCAPTCHA Auto-Solver í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**ëª©í‘œ**: Hand-crafted features + ML classifiersë¡œ reCAPTCHA ì´ë¯¸ì§€ ë¶„ë¥˜ ìë™í™”

**ì ‘ê·¼ ë°©ì‹**: 
- ë”¥ëŸ¬ë‹ ëŒ€ì‹  ìˆ˜ë™ íŠ¹ì§• ì¶”ì¶œ (HOG, Color Histogram, LBP, Gradient, Texture)
- ML ë¶„ë¥˜ê¸° (SVM, Random Forest, K-NN, Logistic Regression, XGBoost, AdaBoost)
- K-fold Cross-Validationìœ¼ë¡œ ë°ì´í„° ë¶„í• 
- Feature selection, Ensemble methods ì ìš©

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
Recaptcha/
â”œâ”€â”€ data/                          # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ raw/                       # ì›ë³¸ ë‹¤ìš´ë¡œë“œ ë°ì´í„° (Kaggleì—ì„œ ë°›ì€ ê·¸ëŒ€ë¡œ)
â”‚   â”‚   â”œâ”€â”€ google-recaptcha/      # ë°ì´í„°ì…‹ 1
â”‚   â”‚   â”œâ”€â”€ test-dataset/          # ë°ì´í„°ì…‹ 2
â”‚   â”‚   â””â”€â”€ google-recaptcha-v2/   # ë°ì´í„°ì…‹ 3
â”‚   â”œâ”€â”€ processed/                 # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
â”‚   â”‚   â”œâ”€â”€ images/                # ëª¨ë“  ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (K-foldìš©)
â”‚   â”‚   â”œâ”€â”€ metadata.csv           # ì´ë¯¸ì§€ ê²½ë¡œì™€ ë ˆì´ë¸” ì •ë³´
â”‚   â”‚   â””â”€â”€ label_mapping.json     # í´ë˜ìŠ¤ ì´ë¦„ â†” ìˆ«ì ë§¤í•‘
â”‚   â””â”€â”€ features/                  # ì¶”ì¶œëœ íŠ¹ì§• ë²¡í„°
â”‚       â”œâ”€â”€ hog/                   # HOG íŠ¹ì§•ë§Œ
â”‚       â”‚   â”œâ”€â”€ train_features.npy
â”‚       â”‚   â”œâ”€â”€ train_labels.npy
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ color_hist/            # Color Histogram íŠ¹ì§•ë§Œ
â”‚       â”œâ”€â”€ lbp/                   # LBP íŠ¹ì§•ë§Œ
â”‚       â””â”€â”€ combined/              # ëª¨ë“  íŠ¹ì§• ê²°í•©
â”‚           â”œâ”€â”€ train_features.npy
â”‚           â”œâ”€â”€ train_labels.npy
â”‚           â”œâ”€â”€ visualizations/   # íŠ¹ì§• ì‹œê°í™” ì´ë¯¸ì§€ë“¤
â”‚           â””â”€â”€ statistics.json
â”‚
â”œâ”€â”€ models/                        # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
â”‚   â”œâ”€â”€ svm_combined_model.pkl
â”‚   â”œâ”€â”€ svm_combined_scaler.pkl
â”‚   â”œâ”€â”€ ensemble_model.pkl
â”‚   â””â”€â”€ results/                   # í•™ìŠµ ê²°ê³¼
â”‚       â”œâ”€â”€ kfold_results/         # K-foldë³„ ê²°ê³¼
â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚       â”œâ”€â”€ roc_curves.png
â”‚       â”œâ”€â”€ learning_curves.png
â”‚       â”œâ”€â”€ feature_importance.png
â”‚       â”œâ”€â”€ metrics.json
â”‚       â””â”€â”€ training_log.json
â”‚
â”œâ”€â”€ src/                           # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ download.py                # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (API ë˜ëŠ” ìˆ˜ë™)
â”‚   â”œâ”€â”€ preprocess.py              # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ feature_extraction.py      # íŠ¹ì§• ì¶”ì¶œ
â”‚   â”œâ”€â”€ feature_selection.py       # íŠ¹ì§• ì„ íƒ (PCA, SelectKBest ë“±)
â”‚   â”œâ”€â”€ visualization.py           # íŠ¹ì§• ì‹œê°í™”
â”‚   â”œâ”€â”€ train.py                   # ML ëª¨ë¸ í•™ìŠµ (K-fold í¬í•¨)
â”‚   â”œâ”€â”€ ensemble.py                # ì•™ìƒë¸” ëª¨ë¸
â”‚   â””â”€â”€ evaluate.py                # ëª¨ë¸ í‰ê°€
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter ë…¸íŠ¸ë¶ (ë¶„ì„ìš©)
â”‚   â””â”€â”€ exploration.ipynb
â”‚
â”œâ”€â”€ config/                        # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ config.yaml               # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
â”‚
â”œâ”€â”€ scripts/                       # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ run_pipeline.sh           # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
â”‚   â””â”€â”€ extract_features.sh       # íŠ¹ì§• ì¶”ì¶œë§Œ ì‹¤í–‰
â”‚
â”œâ”€â”€ requirements.txt               # Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ README.md                      # í”„ë¡œì íŠ¸ ì„¤ëª…
â””â”€â”€ PROJECT_STRUCTURE.md           # ì´ ë¬¸ì„œ
```

---

## ğŸ”„ ë°ì´í„° íë¦„ (Pipeline)

```
1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (download.py)
   â””â”€> data/raw/ (ì›ë³¸ ë°ì´í„°)

2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (preprocess.py)
   â””â”€> data/processed/ (ì •ê·œí™”ëœ ì´ë¯¸ì§€)
       - RGB â†’ HSV ë³€í™˜
       - Histogram Equalization
       - í¬ê¸° í†µì¼ (224x224)
       - K-fold ë¶„í•  ì¤€ë¹„ (ë¶„í• ì€ train.pyì—ì„œ ìˆ˜í–‰)

3. íŠ¹ì§• ì¶”ì¶œ (feature_extraction.py)
   â””â”€> data/features/ (íŠ¹ì§• ë²¡í„°)
       - HOG: 1764ì°¨ì›
       - Color Histogram: 96ì°¨ì›
       - LBP: 26ì°¨ì›
       - Gradient: 64ì°¨ì›
       - Texture (GLCM): 60ì°¨ì›
       - Combined: 2010ì°¨ì›

4. ì‹œê°í™” (visualization.py)
   â””â”€> data/features/*/visualizations/ (íˆíŠ¸ë§µ, ì°¨íŠ¸ ë“±)

5. íŠ¹ì§• ì„ íƒ (feature_selection.py) - ì„ íƒì 
   â””â”€> ì°¨ì› ì¶•ì†Œ, ì¤‘ìš” íŠ¹ì§• ì„ íƒ

6. ëª¨ë¸ í•™ìŠµ (train.py)
   â””â”€> K-fold Cross-Validation
   â””â”€> ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
   â””â”€> models/ (í•™ìŠµëœ ëª¨ë¸)

7. ëª¨ë¸ í‰ê°€ (evaluate.py)
   â””â”€> K-fold ê²°ê³¼ í†µí•©
   â””â”€> models/results/ (ì„±ëŠ¥ ì§€í‘œ, í˜¼ë™ í–‰ë ¬, ROC ê³¡ì„  ë“±)
```

---

## ğŸ“ ê° ëª¨ë“ˆ ìƒì„¸ ì„¤ê³„

### 1. `src/download.py` - ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

**ê¸°ëŠ¥**:
- Kaggle APIë¥¼ ì‚¬ìš©í•˜ì—¬ 3ê°œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ì„ íƒì )
- ë˜ëŠ” ë¡œì»¬ì— ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©
- ë°ì´í„°ì…‹ êµ¬ì¡° íƒìƒ‰ ë° ê²€ì¦
- ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸ ë° ì—ëŸ¬ ì²˜ë¦¬

**ì…ë ¥**: 
- ì˜µì…˜ 1: Kaggle API í† í° (`~/.kaggle/kaggle.json`)
- ì˜µì…˜ 2: ë¡œì»¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš°)

**ì¶œë ¥**: 
- `data/raw/` ë””ë ‰í† ë¦¬ì— ì›ë³¸ ë°ì´í„° ì €ì¥
- `data/raw/dataset_info.json` (ë°ì´í„°ì…‹ í†µê³„)

**ì£¼ìš” í•¨ìˆ˜**:
```python
def download_from_kaggle(dataset_name, output_dir)
def use_local_data(local_path, output_dir)
def validate_dataset_structure(data_dir)
def explore_dataset(data_dir) -> dataset_info
def main()
```

**ì‹œê°í™”**:
- ë°ì´í„°ì…‹ êµ¬ì¡° íŠ¸ë¦¬ ë‹¤ì´ì–´ê·¸ë¨
- í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ ë°” ì°¨íŠ¸
- ìƒ˜í”Œ ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ

---

### 2. `src/preprocess.py` - ì´ë¯¸ì§€ ì „ì²˜ë¦¬

**ê¸°ëŠ¥**:
- ì´ë¯¸ì§€ ìƒ‰ìƒ ê³µê°„ ë³€í™˜ (RGB â†’ HSV/Lab)
- Histogram Equalization (CLAHE)
- ì´ë¯¸ì§€ í¬ê¸° í†µì¼ (224x224)
- ë°ì´í„° ì¦ê°• (Data Augmentation) - íšŒì „, ë’¤ì§‘ê¸°, ë°ê¸° ì¡°ì •
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE, Undersampling ë“±)
- Train/Val/Test ë¶„í•  (Stratified Splitìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)

**ì…ë ¥**: `data/raw/` ë””ë ‰í† ë¦¬

**ì¶œë ¥**: 
- `data/processed/images/` (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€)
- `data/processed/metadata.csv` (ì´ë¯¸ì§€ ê²½ë¡œì™€ ë ˆì´ë¸”)
- `data/processed/label_mapping.json` (í´ë˜ìŠ¤ ë§¤í•‘)
- `data/processed/preprocessing_report.html` (ì „ì²˜ë¦¬ ê²°ê³¼ ë¦¬í¬íŠ¸)

**ì‹œê°í™”**:
- ì „ì²˜ë¦¬ ì „/í›„ ì´ë¯¸ì§€ ë¹„êµ
- ìƒ‰ìƒ ê³µê°„ ë³€í™˜ ì‹œê°í™”
- Histogram Equalization íš¨ê³¼ ë¹„êµ
- í´ë˜ìŠ¤ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
- `data/processed/preprocessing_report.html` (ì „ì²˜ë¦¬ í†µê³„ ë¦¬í¬íŠ¸)

**ì£¼ìš” í•¨ìˆ˜**:
```python
def preprocess_image(image) -> processed_image
def convert_color_space(image, target_space='HSV')
def apply_histogram_equalization(image)
def augment_image(image) -> augmented_images
def handle_class_imbalance(images, labels) -> balanced_data
def stratified_split(images, labels, ratios) -> train, val, test
def create_metadata(image_paths, labels)
def generate_preprocessing_report(data_stats)
def main()
```

**ì‹œê°í™”**:
- ì „ì²˜ë¦¬ ì „/í›„ ì´ë¯¸ì§€ ë¹„êµ
- í´ë˜ìŠ¤ë³„ ë°ì´í„° ë¶„í¬ (íŒŒì´ ì°¨íŠ¸, ë°” ì°¨íŠ¸)
- ìƒ‰ìƒ ê³µê°„ ë³€í™˜ ì‹œê°í™”
- Histogram Equalization íš¨ê³¼ ë¹„êµ
- ë°ì´í„° ì¦ê°• ìƒ˜í”Œ ê·¸ë¦¬ë“œ

---

### 3. `src/feature_extraction.py` - íŠ¹ì§• ì¶”ì¶œ

**ê¸°ëŠ¥**:
- HOG (Histogram of Oriented Gradients) íŠ¹ì§• ì¶”ì¶œ
- Color Histogram íŠ¹ì§• ì¶”ì¶œ
- LBP (Local Binary Patterns) íŠ¹ì§• ì¶”ì¶œ
- Gradient íŠ¹ì§• ì¶”ì¶œ
- Texture (GLCM) íŠ¹ì§• ì¶”ì¶œ
- íŠ¹ì§• ê²°í•© ë° ì €ì¥
- íŠ¹ì§• ìƒê´€ê´€ê³„ ë¶„ì„
- íŠ¹ì§• ì¤‘ìš”ë„ ê³„ì‚°

**ì…ë ¥**: `data/processed/` ë””ë ‰í† ë¦¬

**ì¶œë ¥**: 
- `data/features/*/all_features.npy` (ì „ì²´ íŠ¹ì§• ë²¡í„°)
- `data/features/*/all_labels.npy` (ì „ì²´ ë ˆì´ë¸”)
- `data/features/*/statistics.json` (íŠ¹ì§• í†µê³„)
- `data/features/*/feature_correlation.png` (íŠ¹ì§• ê°„ ìƒê´€ê´€ê³„)

**ì‹œê°í™”**:
- ê° íŠ¹ì§•ì˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
- íŠ¹ì§• ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
- íŠ¹ì§• ì¤‘ìš”ë„ (ë¶„ì‚° ê¸°ë°˜)
- `data/features/*/feature_analysis.json` (íŠ¹ì§• ë¶„ì„ ê²°ê³¼)

**ì£¼ìš” í´ë˜ìŠ¤/í•¨ìˆ˜**:
```python
class FeatureExtractor:
    def extract_hog(image) -> features (1764ì°¨ì›)
    def extract_color_histogram(image) -> features (96ì°¨ì›)
    def extract_lbp(image) -> features (26ì°¨ì›)
    def extract_gradient(image) -> features (64ì°¨ì›)
    def extract_texture(image) -> features (60ì°¨ì›)
    def extract_combined(image) -> features (2010ì°¨ì›)

def extract_features_from_dataset(data_dir, feature_type)
def analyze_feature_correlation(features, labels)
def calculate_feature_importance(features, labels)
def save_features(features, labels, output_dir)
def main()
```

**ì‹œê°í™”**:
- íŠ¹ì§•ë³„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
- íŠ¹ì§• ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
- íŠ¹ì§• ì¤‘ìš”ë„ ë°” ì°¨íŠ¸
- íŠ¹ì§• ì°¨ì›ë³„ ë¶„ì‚° ë¶„ì„
- í´ë˜ìŠ¤ë³„ íŠ¹ì§• ë¶„í¬ ë¹„êµ

---

### 4. `src/visualization.py` - íŠ¹ì§• ì‹œê°í™”

**ê¸°ëŠ¥**:
- ì „ì²˜ë¦¬ ê³¼ì • ì‹œê°í™” (ì›ë³¸ â†’ HSV â†’ í‰í™œí™”)
- ê° íŠ¹ì§•ì˜ íˆíŠ¸ë§µ ìƒì„±
- íŠ¹ì§• ë¶„í¬ ë° í†µê³„ ì‹œê°í™”
- ìƒ˜í”Œ ì´ë¯¸ì§€ë³„ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±

**ì…ë ¥**: 
- `data/processed/` (ì´ë¯¸ì§€)
- `data/features/` (íŠ¹ì§• ë²¡í„°)

**ì¶œë ¥**: 
- `data/features/*/visualizations/*.png` (20ê°œ íŒ¨ë„ ì‹œê°í™”)

**ì£¼ìš” í•¨ìˆ˜**:
```python
def visualize_preprocessing(image, processed_image)
def visualize_hog_features(image, hog_features)
def visualize_color_histogram(image, hist_features)
def visualize_lbp_features(image, lbp_features)
def create_comprehensive_report(image_path, features)
def main()
```

**ì‹œê°í™” íŒ¨ë„ êµ¬ì„±** (20ê°œ):
1. ì›ë³¸ ì´ë¯¸ì§€
2. HSV ë³€í™˜
3. Histogram Equalization ë¹„êµ
4. ì „ì²˜ë¦¬ ê²°ê³¼
5. íŠ¹ì§• ë²¡í„° êµ¬ì„±
6-8. HOG ì‹œê°í™” + íˆíŠ¸ë§µ + ì›ë¦¬ ì„¤ëª…
9-10. Color Histogram + ì›ë¦¬ ì„¤ëª…
11-13. LBP íŒ¨í„´ + íˆìŠ¤í† ê·¸ë¨ + ì›ë¦¬ ì„¤ëª…
14-15. Gradient í¬ê¸°/ë°©í–¥
16-20. í†µí•© ë¶„ì„ (íˆíŠ¸ë§µ, í†µê³„, ë¶„í¬, ì¤‘ìš”ë„, ìµœì¢… ìš”ì•½)

---

### 5. `src/train.py` - ML ëª¨ë¸ í•™ìŠµ

**ê¸°ëŠ¥**:
- íŠ¹ì§• ë²¡í„° ë¡œë“œ
- íŠ¹ì§• ì •ê·œí™” (StandardScaler, MinMaxScaler, RobustScaler)
- Feature Selection (SelectKBest, RFE, PCA)
- K-fold Cross Validation (ê¸°ë³¸ 5-fold, Stratified K-Fold)
- ì—¬ëŸ¬ ë¶„ë¥˜ê¸° í•™ìŠµ ë° ë¹„êµ
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (Grid Search, Random Search, Bayesian Optimization)
- ì•™ìƒë¸” ëª¨ë¸ (Voting, Stacking)
- ëª¨ë¸ ì €ì¥ ë° í•™ìŠµ ê³¡ì„  ê¸°ë¡

**ì…ë ¥**: `data/features/*/` (íŠ¹ì§• ë²¡í„°)

**ì¶œë ¥**: 
- `models/*_model.pkl` (í•™ìŠµëœ ëª¨ë¸)
- `models/*_scaler.pkl` (ì •ê·œí™” ìŠ¤ì¼€ì¼ëŸ¬)
- `models/*_selector.pkl` (Feature Selector)
- `models/results/*_metrics.json` (ì„±ëŠ¥ ì§€í‘œ)
- `models/results/cv_results.json` (K-fold ê²°ê³¼)
- `models/results/training_curves.png` (í•™ìŠµ ê³¡ì„ )

**ì‹¤í–‰ í™˜ê²½**:
- **ë§¥ë¶ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥**: 
  - CPU ê¸°ë°˜ ML í•™ìŠµ (SVM, Random Forest, XGBoost ë“±)
  - ì†Œê·œëª¨~ì¤‘ê·œëª¨ ë°ì´í„°ì…‹ (~10K-50K ì´ë¯¸ì§€) ì²˜ë¦¬ ê°€ëŠ¥
  - íŠ¹ì§• ì¶”ì¶œ: CPUë¡œ ì¶©ë¶„ (ë³‘ë ¬ ì²˜ë¦¬ í™œìš©)
  - í•™ìŠµ ì‹œê°„: ë¶„ë¥˜ê¸°ì™€ ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ìˆ˜ë¶„~ìˆ˜ì‹­ë¶„
  - ë©”ëª¨ë¦¬: 8GB RAM ì´ìƒ ê¶Œì¥ (íŠ¹ì§• ë²¡í„° ë©”ëª¨ë¦¬ ì‚¬ìš©)
- **Colab ì‚¬ìš© ê¶Œì¥ ê²½ìš°**:
  - ëŒ€ê·œëª¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)
  - ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ í•™ìŠµ ë° ë¹„êµ
  - GPU ê°€ì†ì´ í•„ìš”í•œ ê²½ìš° (í•˜ì§€ë§Œ ì „í†µ MLì€ CPUë¡œ ì¶©ë¶„)

**ì£¼ìš” í•¨ìˆ˜**:
```python
def load_features(feature_dir, split='train')
def normalize_features(X_train, X_val, method='standard')
def select_features(X_train, y_train, method='pca', n_components=100)
def k_fold_cross_validation(X, y, classifier, k=5, stratified=True)
def optimize_hyperparameters(X_train, y_train, classifier_type, method='grid')
def train_model(X_train, y_train, X_val, y_val, classifier)
def create_ensemble(models, method='voting')
def plot_training_curves(cv_results)
def save_model(model, scaler, selector, output_path)
def main()
```

**ì§€ì›í•˜ëŠ” ë¶„ë¥˜ê¸°**:
- SVM (Support Vector Machine) - Linear, RBF, Polynomial kernels
- Random Forest
- XGBoost (Gradient Boosting)
- LightGBM (Light Gradient Boosting)
- K-NN (K-Nearest Neighbors)
- Logistic Regression
- Naive Bayes (Gaussian, Multinomial)
- Decision Tree
- AdaBoost
- Gradient Boosting

**ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•**:
- **K-fold Cross Validation**: Stratified K-foldë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- **Feature Selection**: SelectKBest, RFE, PCAë¡œ ë¶ˆí•„ìš”í•œ íŠ¹ì§• ì œê±° ë° ì°¨ì› ì¶•ì†Œ
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**: GridSearchCV, RandomSearchCV, Bayesian Optimization
- **ì•™ìƒë¸”**: Voting Classifier, Stacking Classifierë¡œ ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©
- **í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •**: ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ (class_weight='balanced')
- **Feature Scaling**: StandardScaler, MinMaxScaler, RobustScaler
- **SMOTE**: ì†Œìˆ˜ í´ë˜ìŠ¤ ì˜¤ë²„ìƒ˜í”Œë§ (ì„ íƒì )
- **Early Stopping**: XGBoost, LightGBMì—ì„œ ê³¼ì í•© ë°©ì§€

**ì‹œê°í™”**:
- K-fold CV ê²°ê³¼ ë°•ìŠ¤í”Œë¡¯
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” íˆíŠ¸ë§µ
- í•™ìŠµ ê³¡ì„  (Accuracy, Loss)
- Feature Importance ì°¨íŠ¸
- ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë°” ì°¨íŠ¸
- í•™ìŠµ ì‹œê°„ ë¹„êµ

---

### 6. `src/evaluate.py` - ëª¨ë¸ í‰ê°€

**ê¸°ëŠ¥**:
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€
- ì •í™•ë„, Precision, Recall, F1-Score, AUC ê³„ì‚°
- í˜¼ë™ í–‰ë ¬(Confusion Matrix) ìƒì„±
- í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
- ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ë¶„ì„
- ëª¨ë¸ ë¹„êµ (ì—¬ëŸ¬ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ)
- ROC Curve, Precision-Recall Curve ìƒì„±

**ì…ë ¥**: 
- `models/*_model.pkl` (í•™ìŠµëœ ëª¨ë¸)
- `data/features/*/test_*.npy` (í…ŒìŠ¤íŠ¸ íŠ¹ì§•)

**ì¶œë ¥**: 
- `models/results/confusion_matrix.png`
- `models/results/classification_report.txt`
- `models/results/metrics.json`
- `models/results/roc_curve.png`
- `models/results/pr_curve.png`
- `models/results/model_comparison.png`
- `models/results/misclassified_samples/` (ì˜¤ë¶„ë¥˜ ì´ë¯¸ì§€)

**ì£¼ìš” í•¨ìˆ˜**:
```python
def load_model(model_path)
def evaluate_model(model, X_test, y_test)
def plot_confusion_matrix(y_true, y_pred, class_names)
def plot_roc_curve(y_true, y_proba, class_names)
def plot_pr_curve(y_true, y_proba, class_names)
def analyze_misclassifications(model, X_test, y_test, image_paths)
def compare_models(model_results)
def generate_report(metrics, confusion_matrix)
def main()
```

**ì‹œê°í™”**:
- í˜¼ë™ í–‰ë ¬ íˆíŠ¸ë§µ
- ROC Curve (ê° í´ë˜ìŠ¤ë³„)
- Precision-Recall Curve
- ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë°” ì°¨íŠ¸
- í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¹„êµ
- ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ
- ì˜ˆì¸¡ í™•ë¥  ë¶„í¬

---

## âš™ï¸ ì„¤ì • íŒŒì¼ (`config/config.yaml`)

```yaml
# ë°ì´í„° ì„¤ì •
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  features_dir: "data/features"
  
  # ë°ì´í„°ì…‹ ëª©ë¡
  datasets:
    - name: "sanjeetsinghnaik/google-recaptcha"
      output: "google-recaptcha"
    - name: "mikhailma/test-dataset"
      output: "test-dataset"
    - name: "cry2003/google-recaptcha-v2-images"
      output: "google-recaptcha-v2"

# ì „ì²˜ë¦¬ ì„¤ì •
preprocessing:
  target_size: [224, 224]
  color_space: "HSV"  # HSV or Lab
  apply_equalization: true
  equalization_method: "CLAHE"  # CLAHE or Histogram
  # K-foldëŠ” train.pyì—ì„œ ìˆ˜í–‰í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¶„í• í•˜ì§€ ì•ŠìŒ

# íŠ¹ì§• ì¶”ì¶œ ì„¤ì •
features:
  hog:
    cell_size: [8, 8]
    block_size: [16, 16]
    nbins: 9
    enabled: true
  
  color_histogram:
    bins: 32
    enabled: true
  
  lbp:
    num_points: 24
    radius: 3
    enabled: true
  
  gradient:
    enabled: true
  
  texture:
    enabled: true

# ëª¨ë¸ í•™ìŠµ ì„¤ì •
training:
  # K-fold Cross Validation
  use_kfold: true
  k_fold: 5
  stratified: true
  
  # Feature Selection
  feature_selection:
    enabled: true
    method: "pca"  # pca, selectkbest, rfe
    n_components: 100  # PCA ì‚¬ìš© ì‹œ
  
  # ë¶„ë¥˜ê¸° ì„ íƒ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)
  classifiers: ["svm", "random_forest", "xgboost", "lightgbm", "knn"]
  feature_type: "combined"  # hog, color_hist, lbp, combined
  
  # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
  hyperparameter_tuning:
    enabled: true
    method: "grid"  # grid, random, bayesian
    cv: 3
  
  svm:
    kernel: "rbf"
    C: [0.1, 1.0, 10.0, 100.0]
    gamma: ["scale", "auto", 0.001, 0.01]
  
  random_forest:
    n_estimators: [50, 100, 200]
    max_depth: [None, 10, 20, 30]
    min_samples_split: [2, 5, 10]
  
  xgboost:
    n_estimators: 100
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.1, 0.3]
  
  lightgbm:
    n_estimators: 100
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.1, 0.3]
  
  knn:
    n_neighbors: [3, 5, 7, 9]
    weights: ["uniform", "distance"]
  
  logistic_regression:
    max_iter: 1000
    solver: "lbfgs"
    C: [0.1, 1.0, 10.0]
  
  # ì•™ìƒë¸”
  ensemble:
    enabled: true
    method: "voting"  # voting, stacking
    classifiers: ["svm", "random_forest", "xgboost"]

# ì‹œê°í™” ì„¤ì •
visualization:
  num_samples: 20
  dpi: 150
  figure_size: [24, 16]
```

---

## ğŸš€ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

### `scripts/run_pipeline.sh` - ì „ì²´ íŒŒì´í”„ë¼ì¸

```bash
#!/bin/bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

# 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (API ë˜ëŠ” ìˆ˜ë™ ê²€ì¦)
python src/download.py --mode auto  # API ì‚¬ìš©
# ë˜ëŠ”
python src/download.py --mode manual  # ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ê²€ì¦

# 2. ì „ì²˜ë¦¬
python src/preprocess.py

# 3. íŠ¹ì§• ì¶”ì¶œ
python src/feature_extraction.py --feature_type combined

# 4. íŠ¹ì§• ì„ íƒ (ì„ íƒì )
python src/feature_selection.py --method pca --n_components 0.95

# 5. ì‹œê°í™”
python src/visualization.py --num_samples 20

# 6. ëª¨ë¸ í•™ìŠµ (K-fold í¬í•¨)
python src/train.py --classifier svm --feature_type combined --kfold 5

# 7. ì•™ìƒë¸” (ì„ íƒì )
python src/ensemble.py --models svm random_forest xgboost

# 8. í‰ê°€
python src/evaluate.py --model models/svm_combined_model.pkl
```

---

## ğŸ“Š ì˜ˆìƒ ë°ì´í„° í¬ê¸°

- **ì›ë³¸ ë°ì´í„°**: ~500MB - 2GB (ì••ì¶• í•´ì œ í›„)
- **ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€**: ~1-3GB (JPEG, 224x224)
- **íŠ¹ì§• ë²¡í„°**: 
  - HOGë§Œ: ~140MB (9404 samples Ã— 1764 dims Ã— 8 bytes)
  - Combined: ~150MB (9404 samples Ã— 2010 dims Ã— 8 bytes)
- **í•™ìŠµëœ ëª¨ë¸**: ~10-50MB (ë¶„ë¥˜ê¸° ì¢…ë¥˜ì— ë”°ë¼)

---

## ğŸ” ì£¼ìš” ì„¤ê³„ ê²°ì •ì‚¬í•­

1. **ëª¨ë“ˆí™”**: Clean Code ì›ì¹™ ì¤€ìˆ˜ - ë‹¨ì¼ ì±…ì„, ëª…í™•í•œ í•¨ìˆ˜ëª…, DRY
2. **K-fold Cross-Validation**: ë¯¸ë¦¬ ë¶„í• í•˜ì§€ ì•Šê³  í•™ìŠµ ì‹œ ë™ì  ë¶„í• ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
3. **ì„¤ì • íŒŒì¼**: YAMLë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤‘ì•™ ê´€ë¦¬
4. **ì‹œê°í™”**: ëª¨ë“  ë‹¨ê³„ì—ì„œ íŒë‹¨ ê°€ëŠ¥í•œ ì‹œê° ìë£Œ ìƒì„±
5. **ì„±ëŠ¥ ìµœì í™”**: Feature selection, Ensemble, Hyperparameter tuning ì ìš©
6. **í™•ì¥ì„±**: ìƒˆë¡œìš´ íŠ¹ì§•ì´ë‚˜ ë¶„ë¥˜ê¸° ì¶”ê°€ ìš©ì´
7. **ì¬í˜„ì„±**: ì„¤ì • íŒŒì¼ê³¼ ì‹œë“œ ê°’ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥
8. **í”Œë«í¼**: ë§¥ë¶ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥ (Colab ë¶ˆí•„ìš”, ë‹¨ GPU ê°€ì† ì—†ìŒ)

## ğŸ’» ì‹¤í–‰ í™˜ê²½

**ë§¥ë¶ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥**: 
- CPU ê¸°ë°˜ ML í•™ìŠµ (SVM, Random Forest ë“±)
- ì†Œê·œëª¨ ë°ì´í„°ì…‹ (~10K ì´ë¯¸ì§€) ì²˜ë¦¬ ê°€ëŠ¥
- íŠ¹ì§• ì¶”ì¶œì€ CPUë¡œ ì¶©ë¶„íˆ ê°€ëŠ¥
- í•™ìŠµ ì‹œê°„: ë¶„ë¥˜ê¸°ì™€ ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ìˆ˜ë¶„~ìˆ˜ì‹­ë¶„

**Colab ì‚¬ìš© ê¶Œì¥ ê²½ìš°**:
- ëŒ€ê·œëª¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ í•™ìŠµ
- GPU ê°€ì†ì´ í•„ìš”í•œ ê²½ìš° (í•˜ì§€ë§Œ ì „í†µ MLì€ CPUë¡œ ì¶©ë¶„)

## ğŸ“ Clean Code 6ì›ì¹™

1. **Meaningful Names**: ë³€ìˆ˜/í•¨ìˆ˜ëª…ì´ ì˜ë„ë¥¼ ëª…í™•íˆ í‘œí˜„
2. **Functions**: ì‘ê³  ë‹¨ì¼ ì±…ì„, í•œ ê°€ì§€ ì¼ë§Œ ìˆ˜í–‰
3. **Comments**: ì½”ë“œë¡œ ì„¤ëª…ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„ë§Œ ì£¼ì„
4. **Formatting**: ì¼ê´€ëœ ì½”ë“œ ìŠ¤íƒ€ì¼ (PEP 8)
5. **Error Handling**: ëª…í™•í•œ ì˜ˆì™¸ ì²˜ë¦¬ ë° ì—ëŸ¬ ë©”ì‹œì§€
6. **DRY (Don't Repeat Yourself)**: ì¤‘ë³µ ì½”ë“œ ì œê±°, ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ ì‘ì„±

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì´ êµ¬ì¡°ë¡œ ì§„í–‰í•˜ê¸° ì „ì— í™•ì¸í•  ì‚¬í•­:

- [ ] ë””ë ‰í† ë¦¬ êµ¬ì¡°ê°€ ëª…í™•í•œê°€?
- [ ] ê° ëª¨ë“ˆì˜ ì—­í• ì´ ë¶„ëª…í•œê°€?
- [ ] ë°ì´í„° íë¦„ì´ ë…¼ë¦¬ì ì¸ê°€?
- [ ] í•„ìš”í•œ ëª¨ë“  ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- [ ] í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ì¸ê°€?

---

**ì´ êµ¬ì¡°ë¡œ ì§„í–‰í• ê¹Œìš”? ìˆ˜ì •í•  ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”!**
